"use strict";(self.webpackChunkmikechesterwang_github_io=self.webpackChunkmikechesterwang_github_io||[]).push([[618],{3905:function(e,n,r){r.d(n,{Zo:function(){return l},kt:function(){return m}});var t=r(7294);function o(e,n,r){return n in e?Object.defineProperty(e,n,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[n]=r,e}function a(e,n){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),r.push.apply(r,t)}return r}function i(e){for(var n=1;n<arguments.length;n++){var r=null!=arguments[n]?arguments[n]:{};n%2?a(Object(r),!0).forEach((function(n){o(e,n,r[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):a(Object(r)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(r,n))}))}return e}function s(e,n){if(null==e)return{};var r,t,o=function(e,n){if(null==e)return{};var r,t,o={},a=Object.keys(e);for(t=0;t<a.length;t++)r=a[t],n.indexOf(r)>=0||(o[r]=e[r]);return o}(e,n);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(t=0;t<a.length;t++)r=a[t],n.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(o[r]=e[r])}return o}var c=t.createContext({}),u=function(e){var n=t.useContext(c),r=n;return e&&(r="function"==typeof e?e(n):i(i({},n),e)),r},l=function(e){var n=u(e.components);return t.createElement(c.Provider,{value:n},e.children)},p={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},d=t.forwardRef((function(e,n){var r=e.components,o=e.mdxType,a=e.originalType,c=e.parentName,l=s(e,["components","mdxType","originalType","parentName"]),d=u(r),m=o,f=d["".concat(c,".").concat(m)]||d[m]||p[m]||a;return r?t.createElement(f,i(i({ref:n},l),{},{components:r})):t.createElement(f,i({ref:n},l))}));function m(e,n){var r=arguments,o=n&&n.mdxType;if("string"==typeof e||o){var a=r.length,i=new Array(a);i[0]=d;var s={};for(var c in n)hasOwnProperty.call(n,c)&&(s[c]=n[c]);s.originalType=e,s.mdxType="string"==typeof e?e:o,i[1]=s;for(var u=2;u<a;u++)i[u]=r[u];return t.createElement.apply(null,i)}return t.createElement.apply(null,r)}d.displayName="MDXCreateElement"},1997:function(e,n,r){r.r(n),r.d(n,{assets:function(){return l},contentTitle:function(){return c},default:function(){return m},frontMatter:function(){return s},metadata:function(){return u},toc:function(){return p}});var t=r(7462),o=r(3366),a=(r(7294),r(3905)),i=["components"],s={},c="Terraform",u={unversionedId:"DevOps/Terraform",id:"DevOps/Terraform",title:"Terraform",description:"Start a Kubernetes cluster with Terraform and AWS EC2",source:"@site/docs/DevOps/Terraform.md",sourceDirName:"DevOps",slug:"/DevOps/Terraform",permalink:"/docs/DevOps/Terraform",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Makefile",permalink:"/docs/DevOps/Makefile"},next:{title:"convenient_script",permalink:"/docs/DevOps/convenient_script"}},l={},p=[{value:"Start a Kubernetes cluster with Terraform and AWS EC2",id:"start-a-kubernetes-cluster-with-terraform-and-aws-ec2",level:2},{value:"Terraform resource definition",id:"terraform-resource-definition",level:3},{value:"External data script",id:"external-data-script",level:3}],d={toc:p};function m(e){var n=e.components,r=(0,o.Z)(e,i);return(0,a.kt)("wrapper",(0,t.Z)({},d,r,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"terraform"},"Terraform"),(0,a.kt)("h2",{id:"start-a-kubernetes-cluster-with-terraform-and-aws-ec2"},"Start a Kubernetes cluster with Terraform and AWS EC2"),(0,a.kt)("p",null,"Check ",(0,a.kt)("a",{parentName:"p",href:"https://learn.hashicorp.com/tutorials/terraform/aws-build?in=terraform/aws-get-started"},"here")," to know the basic."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'export AWS_ACCESS_KEY_ID="<YOUR_AWS_ACCESS_KEY_ID>"\nexport AWS_SECRET_ACCESS_KEY="<YOUR_AWS_SECRET_ACCESS_KEY>"\nexport AWS_DEFAULT_REGION="<YOUR_AWS_DEFAULT_REGION>"\nterraform init # download dependencies\nterraform plan # for checking\nterraform apply # apply changes to the provider\nterraform destroy # destroy resources created by `terraform apply`\n')),(0,a.kt)("h3",{id:"terraform-resource-definition"},"Terraform resource definition"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-yaml"},'terraform {\n  required_providers {\n    aws = {\n      source  = "hashicorp/aws"\n      version = "~> 3.27"\n    }\n  }\n\n  required_version = ">= 0.14.9"\n}\n\n# Note that if you change the region and \n# run `terraform apply`. The resources in \n# the original region will not be destroyed\n# Because the region is defined in `provider`\n# instead of `resource`\nprovider "aws" {\n  profile = "default"\n  region  = "ap-southeast-1"\n}\n\n# Get default vpc and load it as a terraform resource\n# Every region has a default VPC. Note that this default\n# VPC will not be deleted in `terraform destroy`\nresource "aws_default_vpc" "default" {\n  tags = {\n    Name = "Default VPC"\n  }\n}\n\n# Declare a variable\nvariable "num_workers" {\n  type = number\n}\n\n# A security group that map all  \nresource "aws_security_group" "cluster_node_internal" {\n  name        = "terraform-cluster-node-internal"\n  description = "allow communication between k8s nodes"\n\n  ingress {\n    description = "ssh"\n    from_port   = 22\n    to_port     = 22\n    protocol    = "tcp"\n    cidr_blocks = ["0.0.0.0/0"]\n  }\n\n  ingress {\n    description = "node-10250"\n    from_port   = 10250\n    to_port     = 10250\n    protocol    = "tcp"\n    cidr_blocks = [aws_default_vpc.default.cidr_block]\n  }\n\n  ingress {\n    description = "control-plane-6443"\n    from_port   = 6443\n    to_port     = 6443\n    protocol    = "tcp"\n    cidr_blocks = [aws_default_vpc.default.cidr_block]\n  }\n\n  ingress {\n    description = "worker-node-pod"\n    from_port   = 30000\n    to_port     = 36767\n    protocol    = "tcp"\n    cidr_blocks = [aws_default_vpc.default.cidr_block]\n  }\n\n  egress {\n    from_port        = 0\n    to_port          = 0\n    protocol         = "-1"\n    cidr_blocks      = ["0.0.0.0/0"]\n    ipv6_cidr_blocks = ["::/0"]\n  }\n}\n\nresource "aws_instance" "control_plane" {\n  instance_type = "t2.medium"\n  # The AMI is different in different regions\n  ami           = "ami-0750a20e9959e44ff"\n  key_name      = "custom-cluster"\n\n  tags = {\n    Name = "terraform-k8s-control-plane"\n  }\n\n  security_groups = [\n    aws_security_group.cluster_node_internal.name\n  ]\n  \n  connection {\n    type        = "ssh"\n    user        = "ubuntu"\n    private_key = file("custom-cluster.pem")\n    host        = self.public_ip\n    timeout     = "5m"\n  }\n\n  provisioner "remote-exec" {\n    inline = [\n      "curl -s https://raw.githubusercontent.com/mikechesterwang/setup-kubeadm/main/control-plane-ubuntu20.04.sh | sudo ENDPOINT_IP=${self.private_dns} bash"\n    ]\n  }\n}\n\n# `external` will run external script and \n# get the result. Note that the input \n# and output are all json. It is better to\n# install `jq` to parse input in your script \ndata "external" "kubeadm_secret" {\n\n  depends_on = [\n    aws_instance.control_plane\n  ]\n\n  program = ["bash", "get_join_info.sh"]\n\n  query = {\n    ip               = aws_instance.control_plane.public_ip\n    user             = "ubuntu"\n    private_key_path = "custom-cluster.pem"\n  }\n}\n\n# `output` is for debugging. It will print variables\noutput "token" {\n  value = data.external.kubeadm_secret.result.token\n}\n\noutput "cert" {\n  value = data.external.kubeadm_secret.result.cert\n}\n\nresource "aws_instance" "worker_node" {\n  # Just like a for loop. If `num_workers` is 3, it will \n  # create 3 resources like according to the definition.\n  # You can use ${count.index} to distinguish between them. \n  count = var.num_workers\n\n  instance_type = "t2.medium"\n  ami = "ami-0750a20e9959e44ff"\n  key_name = "custom-cluster"\n\n  tags = {\n    Name = "terraform-k8s-worker-node-${count.index}"\n  }\n\n  security_groups = [\n    aws_security_group.cluster_node_internal.name\n  ]\n\n  connection {\n    type        = "ssh"\n    user        = "ubuntu"\n    private_key = file("custom-cluster.pem")\n    host        = self.public_ip\n    timeout     = "5m"\n  }\n\n  provisioner "remote-exec" {\n    inline = [\n      "curl -s https://raw.githubusercontent.com/mikechesterwang/setup-kubeadm/main/setup-ubuntu20.04.sh | sudo bash",\n      "sudo kubeadm join ${aws_instance.control_plane.private_dns}:6443 --cri-socket unix:///var/run/crio/crio.sock --token ${data.external.kubeadm_secret.result.token} --discovery-token-ca-cert-hash sha256:${data.external.kubeadm_secret.result.cert}"\n    ]\n  }\n}\n\n')),(0,a.kt)("h3",{id:"external-data-script"},"External data script"),(0,a.kt)("p",null,"Since we cannot get the output of ",(0,a.kt)("inlineCode",{parentName:"p"},"remote-exec"),", we will use ",(0,a.kt)("inlineCode",{parentName:"p"},"external")," to run script and get the data from the remote server."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'# Need to use `jq` to parse input\nif ! [ -x "$(command -v jq)" ]; then\n    echo "jq not found, please install jq at first: https://stedolan.github.io/jq/download/" \n    exit 1\nfi\n\n# parse input\neval "$(jq -r \'@sh "user=\\(.user) ip=\\(.ip) private_key_path=\\(.private_key_path)"\')"\n\n# Get `token` and `cert hash` for `kubeadm join`\njq -n --arg token "$(ssh -o "StrictHostKeyChecking no" $user@$ip -i $private_key_path "sudo kubeadm token create")" --arg cert "$(ssh $user@$ip -i $private_key_path "openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | openssl dgst -sha256 -hex | sed \'s/^.* //\'")" \'{"token": $token, "cert": $cert}\'\n')))}m.isMDXComponent=!0}}]);